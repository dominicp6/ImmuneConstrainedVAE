{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c31f4016",
   "metadata": {},
   "source": [
    "# Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c327d46b",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b61ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "\n",
    "# biopython\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "from Bio import pairwise2\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.pairwise2 import format_alignment\n",
    "from Bio.SubsMat import MatrixInfo as matlist\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# pytorch lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "import optuna\n",
    "\n",
    "# ImmunoBERT\n",
    "import pMHC\n",
    "from pMHC.logic import PresentationPredictor\n",
    "from pMHC.data import MhcAllele\n",
    "from pMHC import SEP, \\\n",
    "    SPLITS, SPLIT_TRAIN, SPLIT_VAL, SPLIT_TEST, \\\n",
    "    VIEWS, VIEW_SA, VIEW_SAMA, VIEW_DECONV, \\\n",
    "    INPUT_PEPTIDE, INPUT_CONTEXT\n",
    "from pMHC.data.utils import convert_example_to_batch, move_dict_to_device, get_input_rep_PSEUDO\n",
    "\n",
    "\n",
    "# generative model\n",
    "import SpikeOracle\n",
    "from SpikeOracle import PHASE_TRAIN, PHASE_VALID, PHASE_TEST\n",
    "from SpikeOracle.data import StandardDataset\n",
    "from SpikeOracle.presentation_scoring.IB import score_seq_IB\n",
    "from SpikeOracle.presentation_scoring.nMp import eval_peptides_nMp, score_seq_nMp\n",
    "from SpikeOracle.models.VAE.fc import FcVAE\n",
    "from SpikeOracle.models.VAE.conv import ConvVAE\n",
    "from SpikeOracle.latent import get_latent_from_seq_FcVAE, get_seq_from_latent_FcVAE\n",
    "from SpikeOracle.utils import write_seqs_to_fasta, calc_entropy_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28039145",
   "metadata": {},
   "source": [
    "## constants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64be8e0d",
   "metadata": {},
   "source": [
    "### notebook control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284aa72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_DATA_SPLIT = False\n",
    "\n",
    "RUN_HYP_PARAM_SRCH = False\n",
    "RUN_TRAINING = False\n",
    "RUN_GEN_SEQS = False\n",
    "\n",
    "VERSION = 1\n",
    "CKPT = \"epoch=24-step=25424.ckpt\"\n",
    "CKPT = \"epoch=99-step=101699.ckpt\"\n",
    "\n",
    "LOAD_IB_MODEL = True\n",
    "LOAD_IB_PEPTIDE_SCORES = True\n",
    "SAVE_IB_PEPTIDE_SCORES = True\n",
    "CALIB_IB = False\n",
    "\n",
    "ANTIGENICITY = 2  # 1... ImmunoBERT, 2... netMHCpan\n",
    "\n",
    "FC_EPOCHS = 100\n",
    "FC_SAMPLES = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11306b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder parameters\n",
    "FC_BLOCKS = 5\n",
    "FC_HIDDEN_DIM = 2048 # intermediate dimensions of the encoder\n",
    "\n",
    "# latent space\n",
    "FC_LATENT_DIM = 2   # dimensions of the latent space\n",
    "\n",
    "# VAE parameters\n",
    "FC_KL_TARGET = 0.1    # value of the KL divergence in the loss function\n",
    "\n",
    "# training parameters\n",
    "FC_LR = 3e-4         # the learning rate\n",
    "FC_BATCH_SIZE = 64   # batch size\n",
    "FC_DROPOUT = 0.05\n",
    "FC_WEIGHT_DECAY = 1e-6 # 3e-5\n",
    "\n",
    "# model and data\n",
    "MODEL_NAME = \"FC_004\"\n",
    "FILENAME_TRAIN = f\"..{os.sep}data{os.sep}spikeprot_train.txt\"\n",
    "FILENAME_VALID = f\"..{os.sep}data{os.sep}spikeprot_valid.txt\"\n",
    "FILENAME_TEST = f\"..{os.sep}data{os.sep}spikeprot_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46201547",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME_FASTA = f\"..{os.sep}data{os.sep}spikeprot_final_dataset.afa\"\n",
    "\n",
    "# data constants\n",
    "SEQ_LEN = 1299 # 1449 # 1282  # 18   # restricted to 1271 aa sequence lenghts\n",
    "MAX_SEQ_LEN = SEQ_LEN\n",
    "AA_ENC_DIM = 21   # count of amino acid encoding dimensions\n",
    "SEP = os.sep\n",
    "IMMUNO_CATS = 3\n",
    "\n",
    "# most relevant MHC alleles\n",
    "MHC_list = [\"HLA-A01:01\", \"HLA-A02:01\", \"HLA-A03:01\", \"HLA-A24:02\", \"HLA-A26:01\",\n",
    "            \"HLA-B07:02\", \"HLA-B08:01\", \"HLA-B27:05\", \"HLA-B39:01\", \"HLA-B40:01\", \"HLA-B58:01\", \"HLA-B15:01\"]\n",
    "\n",
    "# ImmunoBERT\n",
    "IB_VERSION = \"CONTEXT-PSEUDO-HEAD_Cls-DECOY_19-LR_0.00001\"\n",
    "IB_CHECKPOINT = \"epoch=4-step=3648186\"\n",
    "IB_PROJ_PATH = r\"C:\\Users\\s2118339\\Documents\\MSc_AI_Thesis_final\\MScProject\"\n",
    "\n",
    "# netMHCpan\n",
    "NMP_FOLDER_1 = f\"..{os.sep}netMHCpan\"\n",
    "NMP_FOLDER_2 = r\"~/win/Documents/2022H1/Group_project/CovidProject/netMHCpan\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011d9302",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8803c661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "if CREATE_DATA_SPLIT:\n",
    "    ds = StandardDataset(SEQ_LEN, MAX_SEQ_LEN)\n",
    "    ds.load_from_fasta(FILENAME_FASTA)\n",
    "    \n",
    "    print(f\"Fasta len: {len(ds.viral_seqs)}\")\n",
    "    \n",
    "    ds_val = ds.splitoff(2000)\n",
    "    ds_test = ds.splitoff(2000)\n",
    "    \n",
    "    print(f\"Train len: {len(ds.viral_seqs)}\")\n",
    "    print(f\"Valid len: {len(ds_val.viral_seqs)}\")\n",
    "    print(f\"Test len: {len(ds_test.viral_seqs)}\")\n",
    "    \n",
    "    ds.save_to_file(FILENAME_TRAIN)\n",
    "    ds_val.save_to_file(FILENAME_VALID)\n",
    "    ds_test.save_to_file(FILENAME_TEST)\n",
    "\n",
    "else:\n",
    "    ds = StandardDataset(SEQ_LEN, MAX_SEQ_LEN, filename=FILENAME_TRAIN)\n",
    "    ds_val = StandardDataset(SEQ_LEN, MAX_SEQ_LEN, filename=FILENAME_VALID)\n",
    "    ds_test = StandardDataset(SEQ_LEN, MAX_SEQ_LEN, filename=FILENAME_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca4dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq in tqdm(ds_val.viral_seqs):\n",
    "    if seq in ds.viral_seqs:\n",
    "        print(f\"Error: {seq}\")\n",
    "        \n",
    "for seq in tqdm(ds_test.viral_seqs):\n",
    "    if seq in ds.viral_seqs:\n",
    "        print(f\"Error: {seq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5297fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_viral_seqs = ds.viral_seqs + ds_val.viral_seqs + ds_test.viral_seqs\n",
    "len(all_viral_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84188588",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds.viral_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713ef57e",
   "metadata": {},
   "source": [
    "## ImmunoBERT assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70110ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be found under https://github.com/hcgasser/ImmunoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aaa63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59a136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ImmunoBERT model\n",
    "if LOAD_IB_MODEL:\n",
    "    pMHC.set_paths(IB_PROJ_PATH)\n",
    "    MODEL_PATH = f\"..{os.sep}data{os.sep}{IB_CHECKPOINT}.ckpt\"\n",
    "    model = PresentationPredictor.load_from_checkpoint(MODEL_PATH,\n",
    "                                                       num_workers=0, shuffle_data=False, output_attentions=False)\n",
    "\n",
    "    model.setup();\n",
    "    model.to(\"cuda\");\n",
    "    model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdc60b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CALIB_IB:\n",
    "    rand_peptides = defaultdict(lambda: {})\n",
    "    for j in tqdm(range(10000)):\n",
    "        rand_peptide = \"\".join([ds.tok.dec_dict[x] for x in np.random.choice(range(1, 21), 9)])\n",
    "        for mhc_name in MHC_list:\n",
    "            example = get_input_rep_PSEUDO(\"\", rand_peptide, \"\", \n",
    "                MhcAllele.mhc_alleles[mhc_name].pseudo_seq, model)\n",
    "            pred = float(torch.sigmoid(model(move_dict_to_device(convert_example_to_batch(example), model))))\n",
    "            rand_peptides[mhc_name][rand_peptide] = pred\n",
    "            \n",
    "    IB_weak_antigenic_threshold = {}\n",
    "    IB_strong_antigenic_threshold = {}\n",
    "    for mhc_name in MHC_list:\n",
    "        IB_weak_antigenic_threshold.update({mhc_name: np.quantile(list(rand_peptides[mhc_name].values()), 0.98)})\n",
    "        IB_strong_antigenic_threshold.update({mhc_name: np.quantile(list(rand_peptides[mhc_name].values()), 0.995)})\n",
    "        \n",
    "    with open(f\"..{os.sep}data{os.sep}IB_weak_antigenic_threshold.pickle\", \"wb\") as file:\n",
    "        pickle.dump(IB_weak_antigenic_threshold, file)\n",
    "        \n",
    "    with open(f\"..{os.sep}data{os.sep}IB_strong_antigenic_threshold.pickle\", \"wb\") as file:\n",
    "        pickle.dump(IB_strong_antigenic_threshold, file)\n",
    "        \n",
    "else:\n",
    "    with open(f\"..{os.sep}data{os.sep}IB_weak_antigenic_threshold.pickle\", \"rb\") as file:\n",
    "        IB_weak_antigenic_threshold = pickle.load(file)\n",
    "        \n",
    "    with open(f\"..{os.sep}data{os.sep}IB_strong_antigenic_threshold.pickle\", \"rb\") as file:\n",
    "        IB_strong_antigenic_threshold = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba5d531",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IB_weak_antigenic_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d455013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IB_strong_antigenic_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714e347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate or load scores for peptide flank combinations\n",
    "IB_peptide_scores = {}\n",
    "IB_seq_scores_50 = defaultdict(lambda: 0)\n",
    "IB_seq_scores_weak = defaultdict(lambda: 0)\n",
    "IB_seq_scores_strong = defaultdict(lambda: 0)\n",
    "IB_seq_avg_scores = defaultdict(lambda: 0)\n",
    "\n",
    "\n",
    "if LOAD_IB_PEPTIDE_SCORES:\n",
    "    with open(f\"..{os.sep}data{os.sep}IB_peptide_scores.pickle\", \"rb\") as file:\n",
    "        IB_peptide_scores = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe7437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically adds peptide scores if they cannot be found to the peptide score dictionary\n",
    "for seq in tqdm(all_viral_seqs):             \n",
    "    IB_seq_scores_50[seq], IB_seq_scores_weak[seq], IB_seq_scores_strong[seq], IB_seq_avg_scores[seq] = \\\n",
    "        score_seq_IB(model, seq,  MHC_list, IB_peptide_scores,\n",
    "                     weak_antigenic_threshold=IB_weak_antigenic_threshold, \n",
    "                     strong_antigenic_threshold=IB_strong_antigenic_threshold)\n",
    "        \n",
    "if SAVE_IB_PEPTIDE_SCORES:\n",
    "    with open(f\"..{os.sep}data{os.sep}IB_peptide_scores.pickle\", \"wb\") as file:\n",
    "        pickle.dump(IB_peptide_scores, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9dfca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete = []\n",
    "for key, values in IB_peptide_scores.items():\n",
    "    if len(values) != len(MHC_list):\n",
    "        to_delete.append(key)\n",
    "        \n",
    "for key in to_delete:\n",
    "    del IB_peptide_scores[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5e1605",
   "metadata": {},
   "outputs": [],
   "source": [
    "IB_seq_scores = IB_seq_scores_weak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622fd485",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.array(list(IB_seq_scores.values()))\n",
    "IB_seq_scores_p25 = np.percentile(h, 25)\n",
    "IB_seq_scores_p75 = np.percentile(h, 75)\n",
    "\n",
    "IB_seq_immuno_cat = {}\n",
    "for seq in all_viral_seqs:\n",
    "    if IB_seq_scores[seq] < IB_seq_scores_p25:\n",
    "        IB_seq_immuno_cat[seq] = 0\n",
    "    elif IB_seq_scores[seq] < IB_seq_scores_p75:\n",
    "        IB_seq_immuno_cat[seq] = 1\n",
    "    else:\n",
    "        IB_seq_immuno_cat[seq] = 2\n",
    "        \n",
    "print(f\"IB_seq_scores_p25: {IB_seq_scores_p25:.5f} IB_seq_scores_p75: {IB_seq_scores_p75:.5f}\")\n",
    "print(f\"mean: {np.mean(list(IB_seq_scores.values())):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17366874",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(np.array(list(IB_seq_scores.values())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939eeafa",
   "metadata": {},
   "source": [
    "## netMHCpan assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641068f",
   "metadata": {},
   "outputs": [],
   "source": [
    "peptides_db = defaultdict(lambda: 0)\n",
    "for key in IB_peptide_scores.keys():\n",
    "    start = key.find(\"_\") + 1\n",
    "    peptides_db[key[start:start+9]] += 1\n",
    "    \n",
    "peptides_db = list(peptides_db.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fe53ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(f\"{NMP_FOLDER_1}{os.sep}peptides_db.pep\", \"w\")\n",
    "for peptide in peptides_db:\n",
    "      file.writelines([peptide, \"\\n\"])\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aece2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run shell script in Linux\n",
    "\n",
    "# folder=/home/tux/win/2022H1/Group_project/CovidProject/netMHCpan\n",
    "# for mhc in A01:01 A02:01 A03:01 A24:02 A26:01 B07:02 B08:01 B27:05 B39:01 B40:01 B58:01 B15:01\n",
    "# do\n",
    "# \t./netMHCpan -p $folder/peptides_db.pep -a HLA-$mhc > $folder/peptides_db_${mhc:0:3}${mhc:4:2}.pep.out\t\n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f52fdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nMp_peptide_scores = eval_peptides_nMp(\"peptides_db\", MHC_list);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef4d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "nMp_seq_scores = defaultdict(lambda : 0)\n",
    "nMp_epitopes_db = set()\n",
    "for seq in tqdm(all_viral_seqs):\n",
    "    nMp_seq_scores[seq], epitopes = score_seq_nMp(seq, MHC_list, nMp_peptide_scores)\n",
    "    nMp_epitopes_db = nMp_epitopes_db.union(epitopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fd84ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(nMp_epitopes_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee977f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = np.array(list(nMp_seq_scores.values()))\n",
    "nMp_seq_scores_p25 = np.percentile(h, 25)\n",
    "nMp_seq_scores_p75 = np.percentile(h, 75)\n",
    "\n",
    "nMp_seq_immuno_cat = {}\n",
    "for seq in all_viral_seqs:\n",
    "    if nMp_seq_scores[seq] < nMp_seq_scores_p25:\n",
    "        nMp_seq_immuno_cat[seq] = 0\n",
    "    elif nMp_seq_scores[seq] < nMp_seq_scores_p75:\n",
    "        nMp_seq_immuno_cat[seq] = 1\n",
    "    else:\n",
    "        nMp_seq_immuno_cat[seq] = 2\n",
    "        \n",
    "print(f\"nMp_seq_scores_p25: {nMp_seq_scores_p25:.5f} nMp_seq_scores_p75: {nMp_seq_scores_p75:.5f}\")\n",
    "print(f\"mean: {np.mean(list(nMp_seq_scores.values()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b2221b",
   "metadata": {},
   "source": [
    "## assign antigenicity category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328a2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANTIGENICITY == 1:\n",
    "    ds.seq_immuno_cat = IB_seq_immuno_cat\n",
    "    ds_val.seq_immuno_cat = IB_seq_immuno_cat\n",
    "    ds_test.seq_immuno_cat = IB_seq_immuno_cat\n",
    "elif ANTIGENICITY == 2:\n",
    "    ds.seq_immuno_cat = nMp_seq_immuno_cat\n",
    "    ds_val.seq_immuno_cat = nMp_seq_immuno_cat\n",
    "    ds_test.seq_immuno_cat = nMp_seq_immuno_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828fd996",
   "metadata": {},
   "source": [
    "# FC VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e75bb",
   "metadata": {},
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cbee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYP_EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f75d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seqs(VAE, n_seqs, antigenicity=0):\n",
    "    hyp_latent_dim = VAE.latent_dim\n",
    "    pl.seed_everything(42)\n",
    "    \n",
    "    # generate random latent variables\n",
    "    p = torch.distributions.Normal(\n",
    "        torch.zeros(hyp_latent_dim, device=VAE.device), \n",
    "        torch.ones(hyp_latent_dim, device=VAE.device))\n",
    "\n",
    "    mus, log_vars, latents, cats = VAE.get_latent_from_seq(VAE.ds[PHASE_VALID].viral_seqs)\n",
    "    \n",
    "    Zs = p.sample(sample_shape=torch.Size([n_seqs])).to(VAE.device)\n",
    "    latents = torch.vstack(latents)\n",
    "    Zs = Zs @ torch.cov(latents.t()).to(VAE.device).float()\n",
    "\n",
    "    generated_seqs = VAE.get_seq_from_latent(Zs, antigenicity) # generate low antigenic sequences\n",
    "    return generated_seqs\n",
    "    \n",
    "\n",
    "def define_model(trial):\n",
    "    hyp_blocks = trial.suggest_int(\"blocks\", 2, 7)\n",
    "    hyp_hidden = trial.suggest_categorical(\"hidden_dim\", [1024*2, 1024, 512])\n",
    "    hyp_latent_dim = trial.suggest_int(\"latent_dim\", 2, 50)\n",
    "    hyp_dropout = trial.suggest_float(\"dropout\", 0.05, 0.5)\n",
    "    hyp_kl_target = trial.suggest_float(\"kl_target\", 0.01, 1.0)\n",
    "    \n",
    "    hyp_VAE = FcVAE(\n",
    "            aa_dim = AA_ENC_DIM,\n",
    "            sequence_len = MAX_SEQ_LEN,\n",
    "            blocks = hyp_blocks,\n",
    "            hidden_dim = hyp_hidden,\n",
    "            hidden_dim_scaling_factor=(0.5, 2.0),\n",
    "            latent_dim = hyp_latent_dim,\n",
    "            conditional = 3,\n",
    "            dropout = hyp_dropout,\n",
    "            kl_target = hyp_kl_target,\n",
    "            lr = FC_LR,\n",
    "            batch_size = FC_BATCH_SIZE,\n",
    "            weight_decay = FC_WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    hyp_VAE.ds[PHASE_TRAIN] = ds\n",
    "    hyp_VAE.ds[PHASE_VALID] = ds_val\n",
    "    hyp_VAE.ds[PHASE_TEST] = ds_test\n",
    "    \n",
    "    return hyp_VAE, hyp_blocks, hyp_hidden, hyp_latent_dim, hyp_kl_target, hyp_dropout\n",
    "\n",
    "def objective(trial):\n",
    "    hyp_VAE, hyp_blocks, hyp_hidden, hyp_latent_dim, hyp_kl_target, hyp_dropout = define_model(trial)\n",
    "    \n",
    "    experiment_name = f\"OPTUNA-LATENT_DIM-{hyp_latent_dim}-BLOCKS-{hyp_blocks}-HIDDEN-{hyp_hidden}-KL_TARGET-{hyp_kl_target:.3f}-DROPOUT-{hyp_dropout:.3f}\"\n",
    "    \n",
    "    logger = TensorBoardLogger(\"tb_logs\", name=experiment_name)    \n",
    "    trainer = Trainer(max_epochs=HYP_EPOCHS, gpus=1, logger=logger)\n",
    "    \n",
    "    trainer.fit(hyp_VAE)\n",
    "    # trainer.save_checkpoint(f\"..{os.sep}models{os.sep}{experiment_name}.ckpt\")\n",
    "    \n",
    "    generated_seqs = generate_seqs(hyp_VAE, 100)\n",
    "    gen_seqs = []\n",
    "    for seq, cnt in generated_seqs.items():\n",
    "        gen_seqs += [seq] * cnt\n",
    "        \n",
    "    ev = calc_entropy_vector(gen_seqs, hyp_VAE.ds[PHASE_TRAIN].tok.aa_to_idx)\n",
    "    \n",
    "    evaluation_score = torch.norm(torch.tensor(ev - ev_train))\n",
    "    \n",
    "    return evaluation_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e249fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    study_name=\"hyp\", storage='sqlite:///hyp.db', load_if_exists=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243482f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_HYP_PARAM_SRCH:\n",
    "    ev_train = calc_entropy_vector(ds.viral_seqs, ds.tok.aa_to_idx)\n",
    "    study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(study.trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16013ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in study.trials:\n",
    "    print(t.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb5f6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = study.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c518a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in trial.params.items():\n",
    "    print(f\" {key:<20s}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc998cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdd885",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ccb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.visualization.plot_contour(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b6c175",
   "metadata": {},
   "source": [
    "## training and loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f278ae51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LOG_PATH = f\".{os.sep}tb_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ed048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_from_trial(trial, version, ckpt):\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\" {key:<20s}: {value}\")\n",
    "    \n",
    "    hyp_latent_dim = trial.params['latent_dim']\n",
    "    hyp_blocks = trial.params['blocks']\n",
    "    hyp_hidden = trial.params['hidden_dim']\n",
    "    hyp_kl_target = trial.params['kl_target']\n",
    "    hyp_dropout = trial.params['dropout']\n",
    "    experiment_name = f\"OPTUNA-LATENT_DIM-{hyp_latent_dim}-BLOCKS-{hyp_blocks}-HIDDEN-{hyp_hidden}-KL_TARGET-{hyp_kl_target:.3f}-DROPOUT-{hyp_dropout:.3f}\"\n",
    "\n",
    "    url = f\"{LOG_PATH}{os.sep}{experiment_name}{os.sep}version_{version}{os.sep}checkpoints{os.sep}{ckpt}\"\n",
    "    \n",
    "    return url, experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc6678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url, experiment_name = url_from_trial(trial, VERSION, CKPT)\n",
    "logger = TensorBoardLogger(\"tb_logs\", name=experiment_name)\n",
    "VAE = FcVAE.load_from_checkpoint(checkpoint_path=url) #f\"..{os.sep}models{os.sep}{MODEL_NAME}.ckpt\")\n",
    "VAE = VAE.cuda()\n",
    "VAE.ds = [ds, ds_val, ds_test]\n",
    "\n",
    "if RUN_TRAINING:\n",
    "    trainer = pl.Trainer(gpus=1,  logger=logger, max_epochs=FC_EPOCHS)\n",
    "    trainer.fit(VAE, ckpt_path=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb1dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAE.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7219f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5761ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "j += 1\n",
    "h = ds.tok.decode(\n",
    "        VAE.forward(\n",
    "            ds.tok.tokenize(ds.viral_seqs[j][:MAX_SEQ_LEN]).unsqueeze(dim=0).to(VAE.device),\n",
    "            torch.tensor(ds.seq_immuno_cat_tokens[ds.seq_immuno_cat[ds.viral_seqs[j]]]).unsqueeze(dim=0).to(VAE.device),\n",
    "            sample=False).reshape(1, MAX_SEQ_LEN, -1)\n",
    ")\n",
    "alignments = pairwise2.align.globalxx(ds.viral_seqs[j][:MAX_SEQ_LEN], h[0])\n",
    "print(format_alignment(*alignments[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0317c9f8",
   "metadata": {},
   "source": [
    "## latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19e6dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mus, log_vars, latents, cats = VAE.get_latent_from_seq(VAE.ds[PHASE_TRAIN].viral_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86122a1",
   "metadata": {},
   "source": [
    "## generate new sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb9c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_seqs = [None, None, None]\n",
    "generated_seqs_new = [None, None, None]\n",
    "antigenicity_names = [\"low\", \"medium\", \"high\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e460bc4",
   "metadata": {},
   "source": [
    "### lowly antigenic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfbe731",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34ef188",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_GEN_SEQS:\n",
    "    generated_seqs[j] = generate_seqs(VAE, FC_SAMPLES, antigenicity=j)\n",
    "\n",
    "    generated_seqs_new[j] = {}\n",
    "    for seq, cnt in generated_seqs[j].items():\n",
    "        if seq not in VAE.ds[PHASE_TRAIN].viral_seqs:\n",
    "            generated_seqs_new[j].update({seq: cnt})\n",
    "\n",
    "    print(f\"Generated: {len(generated_seqs[j])} New: {len(generated_seqs_new[j])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9954b878",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_all = f\"..{os.sep}data{os.sep}spike_protein_sequences{os.sep}{MODEL_NAME}_gen_{antigenicity_names[j]}_all.fasta\"\n",
    "filename_new = f\"..{os.sep}data{os.sep}spike_protein_sequences{os.sep}{MODEL_NAME}_gen_{antigenicity_names[j]}.fasta\"\n",
    "\n",
    "if RUN_GEN_SEQS:\n",
    "    write_seqs_to_fasta(generated_seqs[j], filename_all);\n",
    "    write_seqs_to_fasta(generated_seqs_new[j], filename_new);\n",
    "else:\n",
    "    generated_seqs[j] = {}\n",
    "    for record in SeqIO.parse(filename_all, \"fasta\"):\n",
    "        generated_seqs[j].update({str(record.seq): int(record.id)})\n",
    "\n",
    "    generated_seqs_new[j] = {}\n",
    "    for record in SeqIO.parse(filename_all, \"fasta\"):\n",
    "        generated_seqs_new[j].update({str(record.seq): int(record.id)})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a933444b",
   "metadata": {},
   "source": [
    "### intermediate antigenic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a008b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a6124",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_GEN_SEQS:\n",
    "    generated_seqs[j] = generate_seqs(VAE, FC_SAMPLES, antigenicity=j)\n",
    "\n",
    "    generated_seqs_new[j] = {}\n",
    "    for seq, cnt in generated_seqs[j].items():\n",
    "        if seq not in VAE.ds[PHASE_TRAIN].viral_seqs:\n",
    "            generated_seqs_new[j].update({seq: cnt})\n",
    "\n",
    "    print(f\"Generated: {len(generated_seqs[j])} New: {len(generated_seqs_new[j])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_all = f\"..{os.sep}data{os.sep}spike_protein_sequences{os.sep}{MODEL_NAME}_gen_{antigenicity_names[j]}_all.fasta\"\n",
    "filename_new = f\"..{os.sep}data{os.sep}spike_protein_sequences{os.sep}{MODEL_NAME}_gen_{antigenicity_names[j]}.fasta\"\n",
    "\n",
    "if RUN_GEN_SEQS:\n",
    "    write_seqs_to_fasta(generated_seqs[j], filename_all);\n",
    "    write_seqs_to_fasta(generated_seqs_new[j], filename_new);\n",
    "else:\n",
    "    generated_seqs[j] = {}\n",
    "    for record in SeqIO.parse(filename_all, \"fasta\"):\n",
    "        generated_seqs[j].update({str(record.seq): int(record.id)})\n",
    "\n",
    "    generated_seqs_new[j] = {}\n",
    "    for record in SeqIO.parse(filename_all, \"fasta\"):\n",
    "        generated_seqs_new[j].update({str(record.seq): int(record.id)})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309e7bcf",
   "metadata": {},
   "source": [
    "### highly antigenic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "j = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ceb164",
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_GEN_SEQS:\n",
    "    generated_seqs[j] = generate_seqs(VAE, FC_SAMPLES, antigenicity=j)\n",
    "\n",
    "    generated_seqs_new[j] = {}\n",
    "    for seq, cnt in generated_seqs[j].items():\n",
    "        if seq not in VAE.ds[PHASE_TRAIN].viral_seqs:\n",
    "            generated_seqs_new[j].update({seq: cnt})\n",
    "\n",
    "    print(f\"Generated: {len(generated_seqs[j])} New: {len(generated_seqs_new[j])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8644a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_all = f\"..{os.sep}data{os.sep}spike_protein_sequences{os.sep}{MODEL_NAME}_gen_{antigenicity_names[j]}_all.fasta\"\n",
    "filename_new = f\"..{os.sep}data{os.sep}spike_protein_sequences{os.sep}{MODEL_NAME}_gen_{antigenicity_names[j]}.fasta\"\n",
    "\n",
    "if RUN_GEN_SEQS:\n",
    "    write_seqs_to_fasta(generated_seqs[j], filename_all);\n",
    "    write_seqs_to_fasta(generated_seqs_new[j], filename_new);\n",
    "else:\n",
    "    generated_seqs[j] = {}\n",
    "    for record in SeqIO.parse(filename_all, \"fasta\"):\n",
    "        generated_seqs[j].update({str(record.seq): int(record.id)})\n",
    "\n",
    "    generated_seqs_new[j] = {}\n",
    "    for record in SeqIO.parse(filename_all, \"fasta\"):\n",
    "        generated_seqs_new[j].update({str(record.seq): int(record.id)})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba11ab9",
   "metadata": {},
   "source": [
    "### evaluate antigenicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c79d216",
   "metadata": {},
   "source": [
    "#### with ImmunoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b80b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3):\n",
    "    for seq in tqdm(generated_seqs_new[j].keys()):             \n",
    "        IB_seq_presentation[seq], IB_seq_scores[seq] = score_seq_IB(model, seq,  MHC_list, IB_peptide_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eff4747",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "\n",
    "for j in range(3):\n",
    "    sns.distplot([IB_seq_scores[seq] for seq in generated_seqs_new[j].keys()])\n",
    "\n",
    "plt.legend(labels=[\"low\",\"medium\", \"high\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7995cdb1",
   "metadata": {},
   "source": [
    "#### with netMHCpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5519cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = []\n",
    "for j in range(3):\n",
    "    for seq in tqdm(list(generated_seqs_new[j].keys())):\n",
    "        seq = seq.replace(\"-\", \"\")\n",
    "        for position in range(len(seq)-9):\n",
    "            if seq[position:(position+9)] not in nMp_peptide_scores:\n",
    "                missing.append(seq[position:(position+9)])\n",
    "                \n",
    "file = open(f\"{NMP_FOLDER_1}{os.sep}missing.pep\", \"w\")\n",
    "for peptide in missing:\n",
    "      file.writelines([peptide, \"\\n\"])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa39e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run shell scritp in linux\n",
    "\n",
    "# folder=/home/tux/win/2022H1/Group_project/CovidProject/netMHCpan\n",
    "# for mhc in A01:01 A02:01 A03:01 A24:02 A26:01 B07:02 B08:01 B27:05 B39:01 B40:01 B58:01 B15:01\n",
    "# do\n",
    "# \t./netMHCpan -p $folder/missing.pep -a HLA-$mhc > $folder/missing_${mhc:0:3}${mhc:4:2}.pep.out\t\n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02d4b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "nMp_peptide_scores.update(eval_peptides_nMp(\"missing\", MHC_list));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90564d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nMp_epitopes_gen = [set(), set(), set()]\n",
    "for j in range(3):\n",
    "    for seq in tqdm(generated_seqs_new[j].keys()):\n",
    "        nMp_seq_scores[seq], epitopes = score_seq_nMp(seq, MHC_list, nMp_peptide_scores)\n",
    "        nMp_epitopes_gen[j] = nMp_epitopes_gen[j].union(epitopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51398e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, name in enumerate(antigenicity_names):\n",
    "    print(f\"{name}: antigenic epitopes - {len(nMp_epitopes_gen[j])} \\t\", end=\"\")\n",
    "    print(f\"new antigenic epitopes - {len(nMp_epitopes_gen[j].difference(nMp_epitopes_db))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b328c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "\n",
    "for j in range(3):\n",
    "    sns.distplot([nMp_seq_scores[seq] for seq in generated_seqs_new[j].keys()])\n",
    "\n",
    "plt.legend(labels=[\"low\",\"medium\", \"high\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917b06d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3):\n",
    "    print(nMp_epitopes_gen[j].difference(nMp_epitopes_db))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "320px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
